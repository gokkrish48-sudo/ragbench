experiment:
  name: "ragbench-baseline"
  tracking_uri: "mlruns/"

ingest:
  chunk_size: 512
  chunk_overlap: 64
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  batch_size: 256

retrievers:
  - type: bm25
    top_k: 10
  - type: dense
    top_k: 10
    index: faiss_flat
  - type: hybrid
    top_k: 10
    alpha: 0.6

evaluate:
  metrics:
    - precision
    - recall
    - ndcg
    - mrr
    - hit_rate
  k_values: [1, 3, 5, 10]
  judge_model: null  # set to "claude-sonnet-4-20250514" to enable LLM-as-Judge

optimize:
  method: bayesian
  n_trials: 50
  metric: "ndcg@5"
  search_space:
    chunk_size: [256, 512, 1024]
    top_k: [3, 5, 10, 20]
    alpha: [0.3, 0.5, 0.7, 0.9]
